{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "e2387ee2",
            "metadata": {},
            "source": [
                "### Cleaning XpressJobs data along with getting some descriptions useful for training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f37aefb4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading source: ..\\data\\raw\\jobs\\xpressjobs_ALL_CATEGORIES_CLEAN_20260201_195011.csv\n",
                        "Loaded 1433 rows.\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 1433 entries, 0 to 1432\n",
                        "Data columns (total 11 columns):\n",
                        " #   Column        Non-Null Count  Dtype \n",
                        "---  ------        --------------  ----- \n",
                        " 0   title         1433 non-null   object\n",
                        " 1   company       1427 non-null   object\n",
                        " 2   location      1269 non-null   object\n",
                        " 3   job_type      1426 non-null   object\n",
                        " 4   days_left     1433 non-null   object\n",
                        " 5   level         1433 non-null   object\n",
                        " 6   description   1433 non-null   object\n",
                        " 7   job_url       1433 non-null   object\n",
                        " 8   category      1433 non-null   object\n",
                        " 9   search_term   1433 non-null   object\n",
                        " 10  scraped_date  1433 non-null   object\n",
                        "dtypes: object(11)\n",
                        "memory usage: 123.3+ KB\n",
                        "Missing values: title             0\n",
                        "company           6\n",
                        "location        164\n",
                        "job_type          7\n",
                        "days_left         0\n",
                        "level             0\n",
                        "description       0\n",
                        "job_url           0\n",
                        "category          0\n",
                        "search_term       0\n",
                        "scraped_date      0\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import re\n",
                "import unicodedata\n",
                "\n",
                "\n",
                "RAW_DIR = Path(\"../data/raw/jobs\")\n",
                "PROCESSED_DIR = Path(\"../data/processed\")\n",
                "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.max_colwidth', 100)\n",
                "\n",
                "\n",
                "source_file = RAW_DIR / \"xpressjobs_ALL_CATEGORIES_CLEAN_20260201_195011.csv\"\n",
                "print(f\"Loading source: {source_file}\")\n",
                "\n",
                "try:\n",
                "    df = pd.read_csv(source_file)\n",
                "    print(f\"Loaded {len(df)} rows.\")\n",
                "except FileNotFoundError:\n",
                "    print(\" File not found. Please ensure data is in data/raw/jobs/\")\n",
                "\n",
                "df.head()\n",
                "df.describe()\n",
                "df.info()\n",
                "print(f\"Missing values: {df.isnull().sum()}\")\n",
                "   "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c966d7e9",
            "metadata": {},
            "source": [
                "### Clean XpressJobs Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "65efd07f",
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_html(text):\n",
                "    if pd.isna(text) or not isinstance(text, str):\n",
                "        return \"\"\n",
                "    \n",
                "    text = re.sub(r'<[^>]+>', ' ', text)\n",
                "    text = re.sub(r'&[a-zA-Z]+;', ' ', text)\n",
                "    text = re.sub(r'&#\\d+;', ' ', text)\n",
                "    \n",
                "    return text\n",
                "\n",
                "def normalize_text(text):\n",
                "    \"\"\" Clean text \"\"\"\n",
                "    if pd.isna(text) or not isinstance(text, str):\n",
                "        return \"\"\n",
                "    \n",
                "    text = re.sub(r'\\s+', ' ', text)\n",
                "    text = text.strip()\n",
                "    text = re.sub(r'[^\\w\\s.,;:()\\-+/&]', '', text)\n",
                "    \n",
                "    return text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5f6986f1",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original (first 500 chars):\n",
                        "SAVE JOB We are seeking a seasoned Senior Software Engineer with a strong background in full stack development, particularly in Java and React. The ideal candidate will have extensive experience in building scalable web applications and services. While your primary focus will be on Java and React, experience with Ruby is a significant advantage and will allow you to contribute to our diverse technology stack. Key Responsibilities: Design, develop, and maintain complex, scalable web applications \n",
                        "\n",
                        "================================================================================\n",
                        "\n",
                        "Cleaned:\n",
                        "SAVE JOB We are seeking a seasoned Senior Software Engineer with a strong background in full stack development, particularly in Java and React. The ideal candidate will have extensive experience in building scalable web applications and services. While your primary focus will be on Java and React, experience with Ruby is a significant advantage and will allow you to contribute to our diverse technology stack. Key Responsibilities: Design, develop, and maintain complex, scalable web applications \n"
                    ]
                }
            ],
            "source": [
                "# Testing \n",
                "sampleDes = df['description'].iloc[0]\n",
                "print(sampleDes[:500])\n",
                "print(\"\\n\\nCleaned:\")\n",
                "print(normalize_text(clean_html(sampleDes))[:500])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c7bb5586",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Experience years\n",
                "def extract_years_experience(text):\n",
                "    \"\"\"Extract years of experience.\"\"\"\n",
                "    if pd.isna(text) or not isinstance(text, str):\n",
                "        return None\n",
                "    \n",
                "    patterns = [\n",
                "        r'(\\d+)\\+?\\s*(?:to|-)\\s*(\\d+)\\s*years?',\n",
                "        r'(\\d+)\\+\\s*years?',\n",
                "        r'(\\d+)\\s*years?',\n",
                "    ]\n",
                "    \n",
                "    for pattern in patterns:\n",
                "        match = re.search(pattern, text.lower())\n",
                "        if match:\n",
                "            return int(match.group(1))\n",
                "    \n",
                "    return None\n",
                "# Extract education level\n",
                "def extract_education_level(text):\n",
                "    \"\"\"Extract education requirements.\"\"\"\n",
                "    if pd.isna(text) or not isinstance(text, str):\n",
                "        return None\n",
                "    \n",
                "    text_lower = text.lower()\n",
                "    \n",
                "    if any(term in text_lower for term in ['phd', 'ph.d', 'doctorate']):\n",
                "        return 'PhD'\n",
                "    elif any(term in text_lower for term in ['master', 'msc', 'mba']):\n",
                "        return 'Masters'\n",
                "    elif any(term in text_lower for term in ['bachelor', 'degree', 'bsc']):\n",
                "        return 'Bachelors'\n",
                "    elif any(term in text_lower for term in ['diploma', 'hnd']):\n",
                "        return 'Diploma'\n",
                "    elif any(term in text_lower for term in ['professional certificate', 'certification']):\n",
                "        return 'Certification' # Similar to CIMA\n",
                "    \n",
                "    return None\n",
                "    \n",
                "    \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "id": "02184505",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Description length stats:\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "count     1433.000000\n",
                            "mean      1516.145848\n",
                            "std       1199.763668\n",
                            "min          8.000000\n",
                            "25%        823.000000\n",
                            "50%       1301.000000\n",
                            "75%       1891.000000\n",
                            "max      12788.000000\n",
                            "Name: description_length, dtype: float64"
                        ]
                    },
                    "execution_count": 112,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Clean descriptions\n",
                "df['description_cleaned'] = df['description'].apply(lambda x: normalize_text(clean_html(x)))\n",
                "df['description_length'] = df['description_cleaned'].str.len()\n",
                "\n",
                "print(f\"Description length stats:\")\n",
                "df['description_length'].describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "db9a7123",
            "metadata": {},
            "source": [
                "### ESCO to get Skills extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "id": "bb0591d1",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 13939 ESCO skills\n",
                        " Skills extracted from 1433 jobs\n",
                        "Average skills per job: 5.0\n"
                    ]
                }
            ],
            "source": [
                "# Load ESCO skills data\n",
                "def load_esco_skills():\n",
                "    \"\"\"Load ESCO skills taxonomy.\"\"\"\n",
                "    esco_skills_path = Path(\"../data/raw/esco/skills_en.csv\")\n",
                "    \n",
                "    if not esco_skills_path.exists():\n",
                "        print(\"ESCO skills file not found. Using basic extraction.\")\n",
                "        return None\n",
                "    \n",
                "    esco_skills = pd.read_csv(esco_skills_path)\n",
                "    # Get skill labels (preferred terms)\n",
                "    skill_labels = esco_skills['preferredLabel'].str.lower().tolist()\n",
                "    \n",
                "    print(f\"Loaded {len(skill_labels)} ESCO skills\")\n",
                "    return skill_labels\n",
                "\n",
                "# Extract skills using ESCO taxonomy\n",
                "def extract_skills_esco(text, esco_skills):\n",
                "    \"\"\"Extract skills from text using ESCO taxonomy.\"\"\"\n",
                "    if pd.isna(text) or not isinstance(text, str):\n",
                "        return []\n",
                "    \n",
                "    if esco_skills is None:\n",
                "        return []\n",
                "    \n",
                "    text_lower = text.lower()\n",
                "    \n",
                "    # Find ESCO skills mentioned in the text\n",
                "    found_skills = []\n",
                "    for skill in esco_skills:\n",
                "        if skill in text_lower:\n",
                "            found_skills.append(skill)\n",
                "    \n",
                "    return found_skills\n",
                "\n",
                "# Load ESCO skills once\n",
                "esco_skills = load_esco_skills()\n",
                "\n",
                "# Apply extraction\n",
                "df['extracted_skills'] = df['description_cleaned'].apply(\n",
                "    lambda x: extract_skills_esco(x, esco_skills)\n",
                ")\n",
                "df['skills_count'] = df['extracted_skills'].apply(len)\n",
                "\n",
                "print(f\" Skills extracted from {len(df)} jobs\")\n",
                "print(f\"Average skills per job: {df['skills_count'].mean():.1f}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e6d7bcfc",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading ESCO occupation data...\n",
                        "Loaded 3039 occupations and 129004 skill relations\n",
                        "\n",
                        "Mapping jobs to ESCO occupations...\n",
                        "Extracting required skills from ESCO...\n",
                        "\n",
                        "✓ Jobs mapped to ESCO: 977 (68.2%)\n",
                        "✓ Average required skills per job: 53.3\n"
                    ]
                }
            ],
            "source": [
                "# Load ESCO data\n",
                "print(\"Loading ESCO occupation data...\")\n",
                "esco_occ = pd.read_csv(\"../data/raw/esco/occupations_en.csv\")\n",
                "esco_relations = pd.read_csv(\"../data/raw/esco/occupationSkillRelations_en.csv\")\n",
                "esco_skills_df = pd.read_csv(\"../data/raw/esco/skills_en.csv\")\n",
                "\n",
                "print(f\"Loaded {len(esco_occ)} occupations and {len(esco_relations)} skill relations\")\n",
                "\n",
                "# Map jobs to ESCO occupations \n",
                "print(\"\\nMapping jobs to ESCO occupations...\")\n",
                "df['esco_occupation_uri'] = df['title'].apply(\n",
                "    lambda x: map_job_to_esco_occupation(x, esco_occ)\n",
                ")\n",
                "\n",
                "# Get required skills for each occupation\n",
                "print(\"Extracting required skills from ESCO...\")\n",
                "df['required_skills_esco'] = df['esco_occupation_uri'].apply(\n",
                "    lambda x: get_skills_for_occupation(x, esco_relations, esco_skills_df)\n",
                ")\n",
                "\n",
                "df['required_skills_count'] = df['required_skills_esco'].apply(len)\n",
                "\n",
                "# Show mapping stats\n",
                "print(f\"\\ Jobs mapped to ESCO: {df['esco_occupation_uri'].notna().sum()} ({df['esco_occupation_uri'].notna().sum()/len(df)*100:.1f}%)\")\n",
                "print(f\" Average required skills per job: {df[df['esco_occupation_uri'].notna()]['required_skills_count'].mean():.1f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "daf65ece",
            "metadata": {},
            "outputs": [],
            "source": [
                "def map_job_to_esco_occupation(job_title, esco_occupations):\n",
                "    \"\"\"Map job title to ESCO occupation with improved fuzzy matching.\"\"\"\n",
                "    if pd.isna(job_title):\n",
                "        return None\n",
                "    \n",
                "    job_lower = job_title.lower()\n",
                "    \n",
                "    # Remove common modifiers that don't change core occupation\n",
                "    modifiers = ['senior', 'junior', 'lead', 'principal', 'assistant', 'associate', \n",
                "                 'chief', 'head', 'mid-level', 'entry-level', 'grade ii', 'grade i',\n",
                "                 'probationary', 'cum', 'male', 'female', '/', '-', '(', ')']\n",
                "    \n",
                "    job_core = job_lower\n",
                "    for mod in modifiers:\n",
                "        job_core = job_core.replace(mod, ' ')\n",
                "    \n",
                "    # Clean up extra spaces\n",
                "    job_core = ' '.join(job_core.split())\n",
                "    \n",
                "    # Define key occupation terms to look for \n",
                "    occupation_patterns = {\n",
                "        'software engineer': ['software engineer', 'software developer', 'developer', 'engineer', 'app lead', 'tech lead', 'full stack', 'backend', 'frontend', 'front end'],\n",
                "         'mobile application developer': ['android', 'ios', 'mobile app', 'mobile developer'],\n",
                "        'lecturer': ['lecturer', 'instructor', 'teacher', 'professor'],\n",
                "        ' business analyst': ['business analyst', 'analyst'],\n",
                "        'architect': ['architect', 'solution architect'],\n",
                "        'system administrator': ['system administrator', 'sysadmin', 'system support', 'workspace administrator', 'appsheet specialist','specialist'],\n",
                "         'data scientist': ['data scientist', 'data analyst', 'ml engineer', 'machine learning'],\n",
                "        'artificial intelligence engineer': ['ai engineer', 'ai app builder', 'ai developer','head of ai'],\n",
                "         'project manager': ['project manager', 'programme manager', 'program manager'],\n",
                "        'sales representative': ['sales executive', 'sales representative', 'sales officer'],\n",
                "        'marketing specialist': ['marketing executive', 'marketing specialist', 'marketing officer'],\n",
                "        'database administrator': ['database administrator', 'dba', 'oracle db'],\n",
                "        ' web developer': ['web developer', 'web designer', 'frontend developer', 'front-end', 'ui/ux designer'],\n",
                "    }\n",
                "    \n",
                "    # pattern matching first\n",
                "    for esco_pattern, variants in occupation_patterns.items():\n",
                "        for variant in variants:\n",
                "            if variant in job_core:\n",
                "                # Find matching ESCO occupation\n",
                "                for idx, occ in esco_occupations.iterrows():\n",
                "                    occ_label = occ['preferredLabel'].lower()\n",
                "                    if esco_pattern in occ_label or any(v in occ_label for v in variants):\n",
                "                        return occ['conceptUri']\n",
                "    \n",
                "    \n",
                "    for idx, occ in esco_occupations.iterrows():\n",
                "        occ_label = occ['preferredLabel'].lower()\n",
                "        \n",
                "        # Check both directions\n",
                "        if occ_label in job_core or job_core in occ_label:\n",
                "            return occ['conceptUri']\n",
                "        \n",
                "        # Word overlap matching (at least 2 significant words)\n",
                "        job_words = set(job_core.split()) - {'and', 'or', 'of', 'the', 'in', 'a', 'an', 'for', 'to'}\n",
                "        occ_words = set(occ_label.split()) - {'and', 'or', 'of', 'the', 'in', 'a', 'an', 'for', 'to'}\n",
                "        \n",
                "        if len(job_words & occ_words) >= 2:\n",
                "            return occ['conceptUri']\n",
                "    \n",
                "    return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 131,
            "id": "3fa607b2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Records with experience: 910 (64.6%)\n",
                        "Records with education: 635 (45.1%)\n",
                        "Average skills per job: 5.1\n"
                    ]
                }
            ],
            "source": [
                "# Extract structured information\n",
                "# Note: Skills are already extracted in the previous cell using ESCO\n",
                "df['years_experience'] = df['description_cleaned'].apply(extract_years_experience)\n",
                "df['education_required'] = df['description_cleaned'].apply(extract_education_level)\n",
                "\n",
                "# Display extraction stats\n",
                "print(f\"Records with experience: {df['years_experience'].notna().sum()} ({df['years_experience'].notna().sum()/len(df)*100:.1f}%)\")\n",
                "print(f\"Records with education: {df['education_required'].notna().sum()} ({df['education_required'].notna().sum()/len(df)*100:.1f}%)\")\n",
                "print(f\"Average skills per job: {df['skills_count'].mean():.1f}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 136,
            "id": "00ad6288",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================================================================\n",
                        "ESCO MAPPING RESULTS\n",
                        "================================================================================\n",
                        "Jobs mapped to ESCO: 960 / 1408 (68.2%)\n",
                        "Average required skills per mapped job: 53.2\n",
                        "\n",
                        " Sample Successful Mappings:\n",
                        "  • Senior Software Engineer : Ruby on Rails → 26 skills\n",
                        "  • Senior Lecturer (Grade II) / Lecturer - Department of Electronics & Telecommunications → 72 skills\n",
                        "  • Senior Lecturer - Grade II / Lecturer / Lecturer (Probationary) - Software Engineering → 26 skills\n",
                        "  • Lecturer cum Programme Manager (IT & Academics) → 72 skills\n",
                        "  • Lecturer - Business & IT → 72 skills\n",
                        "  • Assistant Lecturer - IT → 72 skills\n",
                        "  • Software Engineer / ABAP Developer → 26 skills\n",
                        "  • Mid-Level Software Engineer (React) — POS & Retail Systems → 26 skills\n",
                        "  • Software Engineer (Male) → 26 skills\n",
                        "  • Assistant Lecturer - IT → 72 skills\n",
                        "\n",
                        "Sample Unmapped Jobs (need better matching):\n",
                        "  • UI/UX Designer\n",
                        "  • Technical Lead (NodeJS & ReactJS)\n",
                        "  • Head of Key Accounts - Fashion\n",
                        "  • Specialist - Network Analytics and Automation\n",
                        "  • Head of AI\n",
                        "  • Urgent Technical Assistant (POS Hardware & Software Support)\n",
                        "  • ක්ෂේත්‍ර මෙහෙයුම් නිලධාරී - (පෑලියගොඩ, වත්තල,සහ කඳාන අවට පදිංචිකරුවන් සඳහා විශේෂයි ) / Field Operations Executive - Wattala, Kandana, and Peliyagoda\n",
                        "  • Customer Care Specialist - Recovery Tamil & Sinhala speaking\n",
                        "  • Heavy Machine Mechanic\n",
                        "  • බෙදාහැරීමේ ධාවක (පූර්ණ කාලීන)\n"
                    ]
                }
            ],
            "source": [
                "# Check mapping success rate\n",
                "print(\"=\"*80)\n",
                "print(\"ESCO MAPPING RESULTS\")\n",
                "print(\"=\"*80)\n",
                "print(f\"Jobs mapped to ESCO: {df['esco_occupation_uri'].notna().sum()} / {len(df)} ({df['esco_occupation_uri'].notna().sum()/len(df)*100:.1f}%)\")\n",
                "print(f\"Average required skills per mapped job: {df[df['esco_occupation_uri'].notna()]['required_skills_count'].mean():.1f}\")\n",
                "\n",
                "# Show examples of successful mappings\n",
                "print(\"\\n Sample Successful Mappings:\")\n",
                "mapped_jobs = df[df['esco_occupation_uri'].notna()][['title', 'required_skills_count']].head(10)\n",
                "for idx, row in mapped_jobs.iterrows():\n",
                "    print(f\"  • {row['title']} → {row['required_skills_count']} skills\")\n",
                "\n",
                "# Show examples of unmapped jobs\n",
                "print(\"\\nSample Unmapped Jobs (need better matching):\")\n",
                "unmapped_jobs = df[df['esco_occupation_uri'].isna()]['title'].head(10)\n",
                "for title in unmapped_jobs:\n",
                "    print(f\"  • {title}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 137,
            "id": "dc55a387",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " Created embedding text (avg length: 1568 chars)\n"
                    ]
                }
            ],
            "source": [
                "df['text_for_embedding'] = (\n",
                "    df['title'].fillna('') + ' ' + \n",
                "    df['category'].fillna('') + ' ' + \n",
                "    df['description_cleaned'].fillna('')\n",
                ").str.strip()\n",
                "print(f\" Created embedding text (avg length: {df['text_for_embedding'].str.len().mean():.0f} chars)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 138,
            "id": "31b0f857",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Filtered: 1408 → 1408 jobs\n"
                    ]
                }
            ],
            "source": [
                "initial_count = len(df)\n",
                "df = df.drop_duplicates(subset=['title', 'company'], keep='first')\n",
                "df = df[df['description_cleaned'].str.len() > 100]\n",
                "print(f\"Filtered: {initial_count} → {len(df)} jobs\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 139,
            "id": "bf6d631e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " Data cleaned\n",
                        "Output: ..\\data\\processed\\xpressjobs_cleaned_with_descriptions.csv\n",
                        "Total jobs: 1408\n",
                        "Columns: ['title', 'company', 'location', 'job_type', 'days_left', 'level', 'description', 'job_url', 'category', 'search_term', 'scraped_date', 'description_cleaned', 'description_length', 'extracted_skills', 'skills_count', 'esco_occupation_uri', 'required_skills_esco', 'required_skills_count', 'years_experience', 'education_required', 'text_for_embedding']\n",
                        "\n",
                        "Extraction Stats:\n",
                        "  - Experience: 910 (64.6%)\n",
                        "  - Education: 635 (45.1%)\n",
                        "  - ESCO mapped: 960 (68.2%)\n",
                        "  - Avg skills extracted: 5.1\n",
                        "  - Avg ESCO skills: 53.2\n",
                        "  - Avg text length: 1568 chars\n"
                    ]
                }
            ],
            "source": [
                "# Save cleaned data\n",
                "output_file = PROCESSED_DIR / \"xpressjobs_cleaned_with_descriptions.csv\"\n",
                "df.to_csv(output_file, index=False)\n",
                "\n",
                "\n",
                "print(\" Data cleaned\")\n",
                "\n",
                "print(f\"Output: {output_file}\")\n",
                "print(f\"Total jobs: {len(df)}\")\n",
                "print(f\"Columns: {list(df.columns)}\")\n",
                "print(f\"\\nExtraction Stats:\")\n",
                "print(f\"  - Experience: {df['years_experience'].notna().sum()} ({df['years_experience'].notna().sum()/len(df)*100:.1f}%)\")\n",
                "print(f\"  - Education: {df['education_required'].notna().sum()} ({df['education_required'].notna().sum()/len(df)*100:.1f}%)\")\n",
                "print(f\"  - ESCO mapped: {df['esco_occupation_uri'].notna().sum()} ({df['esco_occupation_uri'].notna().sum()/len(df)*100:.1f}%)\")\n",
                "print(f\"  - Avg skills extracted: {df['skills_count'].mean():.1f}\")\n",
                "print(f\"  - Avg ESCO skills: {df[df['esco_occupation_uri'].notna()]['required_skills_count'].mean():.1f}\")\n",
                "print(f\"  - Avg text length: {df['text_for_embedding'].str.len().mean():.0f} chars\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
