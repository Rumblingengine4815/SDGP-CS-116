{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Market Trend Analysis - ML-Powered Job Market Segmentation\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "\n",
                "# Deep Learning\n",
                "from sentence_transformers import SentenceTransformer\n",
                "import torch\n",
                "\n",
                "# Machine Learning\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.decomposition import PCA\n",
                "\n",
                "# Visualization\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette(\"husl\")\n",
                "\n",
                "print(\" All libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Job Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load processed job data\n",
                "jobs_path = Path(\"../data/processed/all_jobs_master.csv\")\n",
                "jobs_df = pd.read_csv(jobs_path)\n",
                "\n",
                "print(f\"ðŸ“Š Loaded {len(jobs_df)} jobs\")\n",
                "print(f\"\\nColumns: {jobs_df.columns.tolist()}\")\n",
                "\n",
                "# Display sample\n",
                "jobs_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Deep Learning: Generate SBERT Embeddings\n",
                "\n",
                "**SBERT (Sentence-BERT)** converts text into 384-dimensional vectors that capture semantic meaning.\n",
                "\n",
                "### Why SBERT?\n",
                "- Pre-trained on 1 billion sentence pairs\n",
                "- Captures semantic similarity (\"Software Engineer\" â‰ˆ \"Developer\")\n",
                "- Fast inference (~50ms per job)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pre-trained SBERT model\n",
                "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
                "\n",
                "print(f\"Model: {model}\")\n",
                "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare text: Combine title + description snippet\n",
                "jobs_df['combined_text'] = (\n",
                "    jobs_df['title'].fillna('') + \" \" + \n",
                "    jobs_df['description'].fillna('').str[:200]\n",
                ")\n",
                "\n",
                "print(\"Sample combined text:\")\n",
                "print(jobs_df['combined_text'].iloc[0][:200])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate embeddings (this takes ~30 seconds)\n",
                "print(\"Encoding jobs into 384-dimensional vectors...\")\n",
                "\n",
                "embeddings = model.encode(\n",
                "    jobs_df['combined_text'].tolist(),\n",
                "    show_progress_bar=True,\n",
                "    convert_to_tensor=False\n",
                ")\n",
                "\n",
                "print(f\"\\nâœ… Generated embeddings: {embeddings.shape}\")\n",
                "print(f\"   {embeddings.shape[0]} jobs Ã— {embeddings.shape[1]} dimensions\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Machine Learning: K-Means Clustering\n",
                "\n",
                "**K-Means** groups similar jobs into market segments.\n",
                "\n",
                "### How it works:\n",
                "1. Randomly initialize K cluster centers\n",
                "2. Assign each job to nearest center\n",
                "3. Update centers to mean of assigned jobs\n",
                "4. Repeat until convergence"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find optimal number of clusters using Elbow Method\n",
                "inertias = []\n",
                "K_range = range(5, 21)\n",
                "\n",
                "print(\"Testing different cluster counts...\")\n",
                "for k in K_range:\n",
                "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
                "    kmeans.fit(embeddings)\n",
                "    inertias.append(kmeans.inertia_)\n",
                "    print(f\"K={k}: inertia={kmeans.inertia_:.2f}\")\n",
                "\n",
                "# Plot elbow curve\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(K_range, inertias, 'bo-')\n",
                "plt.xlabel('Number of Clusters (K)')\n",
                "plt.ylabel('Inertia (Within-cluster sum of squares)')\n",
                "plt.title('Elbow Method for Optimal K')\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run K-Means with optimal K (let's use 10)\n",
                "n_clusters = 10\n",
                "\n",
                "print(f\"Running K-Means with {n_clusters} clusters...\")\n",
                "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
                "jobs_df['cluster'] = kmeans.fit_predict(embeddings)\n",
                "\n",
                "print(f\"\\n Clustering complete!\")\n",
                "print(f\"\\nCluster distribution:\")\n",
                "print(jobs_df['cluster'].value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualize Clusters (2D Projection)\n",
                "\n",
                "Use **PCA** to reduce 384 dimensions â†’ 2 dimensions for visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reduce dimensions for visualization\n",
                "pca = PCA(n_components=2)\n",
                "embeddings_2d = pca.fit_transform(embeddings)\n",
                "\n",
                "print(f\"Explained variance: {pca.explained_variance_ratio_}\")\n",
                "print(f\"Total variance captured: {pca.explained_variance_ratio_.sum():.2%}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "plt.figure(figsize=(14, 10))\n",
                "scatter = plt.scatter(\n",
                "    embeddings_2d[:, 0],\n",
                "    embeddings_2d[:, 1],\n",
                "    c=jobs_df['cluster'],\n",
                "    cmap='tab10',\n",
                "    alpha=0.6,\n",
                "    s=50\n",
                ")\n",
                "\n",
                "plt.colorbar(scatter, label='Cluster ID')\n",
                "plt.xlabel('First Principal Component')\n",
                "plt.ylabel('Second Principal Component')\n",
                "plt.title('Job Market Clusters (PCA Projection)')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. NLP: Extract Keywords with TF-IDF\n",
                "\n",
                "**TF-IDF** (Term Frequency-Inverse Document Frequency) identifies important words in each cluster."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze each cluster\n",
                "trend_summary = []\n",
                "\n",
                "for i in range(n_clusters):\n",
                "    cluster_data = jobs_df[jobs_df['cluster'] == i]\n",
                "    \n",
                "    # TF-IDF keyword extraction\n",
                "    vectorizer = TfidfVectorizer(stop_words='english', max_features=10)\n",
                "    tfidf_matrix = vectorizer.fit_transform(cluster_data['combined_text'].fillna(''))\n",
                "    keywords = vectorizer.get_feature_names_out()\n",
                "    \n",
                "    # Most common job titles\n",
                "    common_titles = cluster_data['title'].value_counts().head(3).index.tolist()\n",
                "    \n",
                "    trend_summary.append({\n",
                "        \"cluster_id\": i,\n",
                "        \"size\": len(cluster_data),\n",
                "        \"top_titles\": common_titles,\n",
                "        \"key_skills\": keywords.tolist(),\n",
                "        \"market_share\": round((len(cluster_data) / len(jobs_df)) * 100, 2)\n",
                "    })\n",
                "\n",
                "# Convert to DataFrame for better display\n",
                "trends_df = pd.DataFrame(trend_summary)\n",
                "trends_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print detailed report\n",
                "print(\"=\"*60)\n",
                "print(\"SRI LANKAN IT MARKET TREND REPORT (ML-POWERED)\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "for trend in trend_summary:\n",
                "    print(f\"\\n Cluster #{trend['cluster_id']} ({trend['market_share']}% of Market)\")\n",
                "    print(f\" Size: {trend['size']} jobs\")\n",
                "    print(f\" Typical Roles: {', '.join(trend['top_titles'])}\")\n",
                "    print(f\" Primary Skills: {', '.join(trend['key_skills'])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Hot Skills Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract all skills from jobs\n",
                "all_skills = []\n",
                "\n",
                "if 'extracted_skills' in jobs_df.columns:\n",
                "    for skills in jobs_df['extracted_skills'].dropna():\n",
                "        all_skills.extend([s.strip().lower() for s in str(skills).split(\",\") if s.strip()])\n",
                "\n",
                "# Count skill occurrences\n",
                "skill_counts = pd.Series(all_skills).value_counts()\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"TOP 20 HOT SKILLS IN SRI LANKA\")\n",
                "print(f\"{'='*60}\")\n",
                "\n",
                "for skill, count in skill_counts.head(20).items():\n",
                "    print(f\"- {skill.upper()}: found in {count} jobs\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize hot skills\n",
                "plt.figure(figsize=(12, 8))\n",
                "top_skills = skill_counts.head(15)\n",
                "\n",
                "plt.barh(range(len(top_skills)), top_skills.values, color='steelblue')\n",
                "plt.yticks(range(len(top_skills)), [s.upper() for s in top_skills.index])\n",
                "plt.xlabel('Number of Jobs')\n",
                "plt.title('Top 15 Most In-Demand Skills in Sri Lanka', fontsize=14, fontweight='bold')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.grid(axis='x', alpha=0.3)\n",
                "\n",
                "# Add value labels\n",
                "for i, v in enumerate(top_skills.values):\n",
                "    plt.text(v + 5, i, str(v), va='center')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Market Share Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pie chart of market segments\n",
                "plt.figure(figsize=(12, 8))\n",
                "\n",
                "cluster_sizes = jobs_df['cluster'].value_counts().sort_index()\n",
                "labels = [f\"Segment {i}\\n({trends_df.iloc[i]['top_titles'][0]})\" for i in range(n_clusters)]\n",
                "\n",
                "plt.pie(\n",
                "    cluster_sizes.values,\n",
                "    labels=labels,\n",
                "    autopct='%1.1f%%',\n",
                "    startangle=90,\n",
                "    textprops={'fontsize': 9}\n",
                ")\n",
                "\n",
                "plt.title('Sri Lankan IT Job Market Distribution', fontsize=14, fontweight='bold')\n",
                "plt.axis('equal')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Export Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "output_path = Path(\"../data/processed/jobs_with_clusters.csv\")\n",
                "jobs_df.to_csv(output_path, index=False)\n",
                "print(f\" Saved clustered jobs to: {output_path}\")\n",
                "\n",
                "\n",
                "trends_output = Path(\"../data/processed/market_trends.csv\")\n",
                "trends_df.to_csv(trends_output, index=False)\n",
                "print(f\" Saved trend summary to: {trends_output}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
