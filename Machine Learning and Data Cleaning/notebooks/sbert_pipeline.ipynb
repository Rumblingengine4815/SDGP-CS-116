{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "#SBERT RECOMMENDATION ENGINE (THE BRAIN)\n",
                "\n",
                "This notebook implements the core AI logic for PathFinder+.\n",
                "It uses **Sentence-BERT (SBERT)** to understand the *meaning* of skills, not just keywords.\n",
                "\n",
                "**Features Implemented:**\n",
                "1. **Semantic Similarity**: Matching User goals to Courses/Jobs.\n",
                "2. **Skill Gap Analysis**: \"What am I missing for this job?\"\n",
                "3. **Career Paths**: finding the next logical step (e.g. Developer -> Lead).\n",
                "4. **Top-Up Logic**: Recommending Degrees for professionals."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading SBERT Model...\n",
                        "✅ Model Loaded.\n",
                        "Loaded 209 Jobs and 24930 Courses.\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sentence_transformers import SentenceTransformer, util\n",
                "from pathlib import Path\n",
                "\n",
                "# 1. Load Model (Small & Fast)\n",
                "print(\"Loading SBERT Model...\")\n",
                "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "print( \"Model Loaded.\")\n",
                "\n",
                "# 2. Load Data\n",
                "PROCESSED_DIR = Path(\"../data/processed\")\n",
                "jobs_df = pd.read_csv(PROCESSED_DIR / \"jobs_cleaned_sbert_ready.csv\")\n",
                "courses_df = pd.read_csv(PROCESSED_DIR / \"courses_cleaned_sbert_ready.csv\")\n",
                "\n",
                "print(f\"Loaded {len(jobs_df)} Jobs and {len(courses_df)} Courses.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "embedding_gen",
            "metadata": {},
            "source": [
                "## STEP 2: GENERATE EMBEDDINGS (The \"Vectors\")\n",
                "We convert text descriptions into number lists (vectors). This allows math operations on meaning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "make_embs",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generating Job Embeddings...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c9b526beb24249ed80a7ca708bce3ac0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generating Course Embeddings...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0681b91afbe2484a9fd99e535d7b0ecf",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Batches:   0%|          | 0/780 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ Embeddings Ready. Job Shape: (209, 384)\n"
                    ]
                }
            ],
            "source": [
                "def safe_text(row, cols):\n",
                "    # Combine relevant columns for full context\n",
                "    text = \" \"\n",
                "    for col in cols:\n",
                "        if col in row and pd.notna(row[col]):\n",
                "            text += str(row[col]) + \". \"\n",
                "    return text.strip()\n",
                "\n",
                "print(\"Generating Job Embeddings...\")\n",
                "job_texts = jobs_df.apply(lambda x: safe_text(x, ['job_title', 'description']), axis=1).tolist()\n",
                "job_embeddings = model.encode(job_texts, show_progress_bar=True)\n",
                "\n",
                "print(\"Generating Course Embeddings...\")\n",
                "course_texts = courses_df.apply(lambda x: safe_text(x, ['course_name', 'description', 'category']), axis=1).tolist()\n",
                "course_embeddings = model.encode(course_texts, show_progress_bar=True)\n",
                "\n",
                "print(f\"Embeddings Ready. Job Shape: {job_embeddings.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "features",
            "metadata": {},
            "source": [
                "## STEP 3: FEATURE 1 - SKILL GAP & MATCHING\n",
                "The core function: Given a User Profile (Text), find best Jobs and Courses."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "recommender",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "User: I am a student good at mathematics and basic coding. I want to build AI models.\n",
                        "\n",
                        "Recommended Jobs:\n",
                        "                          job_title  similarity\n",
                        "20                      AI Engineer    0.642653\n",
                        "74           AI/ML Engineer Trainee    0.553099\n",
                        "111  Voice/Chat AI Engineer Trainee    0.506865\n",
                        "207      Chatbot Development Intern    0.489125\n",
                        "73          Machine Learning Intern    0.481523\n"
                    ]
                }
            ],
            "source": [
                "def finding_pathfinder_recommendations(user_profile_text, user_level=\"Entry\"):\n",
                "    \"\"\"\n",
                "    user_profile_text: \"I know Python and SQL, want to be a Data Scientist\"\n",
                "    user_level: Current level (Entry, Mid, Senior)\n",
                "    \"\"\"\n",
                "    # 1. Encode User\n",
                "    user_emb = model.encode(user_profile_text)\n",
                "    \n",
                "    # 2. Find Best Job Matches\n",
                "    job_scores = util.cos_sim(user_emb, job_embeddings)[0]\n",
                "    \n",
                "    # Add scores to dataframe\n",
                "    jobs_scored = jobs_df.copy()\n",
                "    jobs_scored['similarity'] = job_scores.cpu().numpy()\n",
                "    \n",
                "    # Filter by level (Optional rule: Don't show Senior jobs to Entry users unless requested)\n",
                "    # best_jobs = jobs_scored[jobs_scored['experience_level'] == user_level] # Example filter\n",
                "    best_jobs = jobs_scored.sort_values('similarity', ascending=False).head(5)\n",
                "    \n",
                "    return best_jobs\n",
                "\n",
                "# TEST IT\n",
                "user_query = \"I am a student good at mathematics and basic coding. I want to build AI models.\"\n",
                "print(f\"User: {user_query}\\n\")\n",
                "recs = finding_pathfinder_recommendations(user_query)\n",
                "print(\"Recommended Jobs:\")\n",
                "print(recs[['job_title', 'similarity']])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "gap_analysis",
            "metadata": {},
            "source": [
                "## STEP 4: FEATURE 2 - SKILL GAP ANALYSIS\n",
                "How to tell the user *what* they are missing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "skill_gap",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Detected Skill Gaps for 'AI Engineer':\n",
                        "['databases', 'llms,', 'pytorch,', 'vector', 'tensorflow,']\n"
                    ]
                }
            ],
            "source": [
                "def analyze_skill_gap(user_text, target_job_description):\n",
                "    # Simple approach: Extract keywords from target that are missing in user text\n",
                "    # (A full semantic subtraction is complex, so we use a set difference proxy)\n",
                "    \n",
                "    user_words = set(user_text.lower().split())\n",
                "    job_words = set(target_job_description.lower().split())\n",
                "    \n",
                "    # Filter for interesting words (simple stopword removal)\n",
                "    stopwords = {'and', 'the', 'to', 'of', 'in', 'a', 'with', 'for'}\n",
                "    missing = [w for w in job_words if w not in user_words and w not in stopwords and len(w) > 4]\n",
                "    \n",
                "    # Rank these missing words by importance (using SBERT to check if they are key concepts)\n",
                "    # For simplicity here, we stick to the top non-matching terms\n",
                "    return list(set(missing))[:5]\n",
                "\n",
                "# DEMO\n",
                "target_job = recs.iloc[0]['description']\n",
                "gaps = analyze_skill_gap(user_query, target_job)\n",
                "print(f\"\\nDetected Skill Gaps for '{recs.iloc[0]['job_title']}':\")\n",
                "print(gaps)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "career_paths",
            "metadata": {},
            "source": [
                "## STEP 5: FEATURE 3 - CAREER PATHS & DEGREES\n",
                "Logic: If user is \"Senior\", suggest \"Postgraduate\". If \"Entry\", suggest \"Diploma/Degree\"."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "career_logic",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Finding Courses for Student to learn: ['databases', 'llms,', 'pytorch,', 'vector', 'tensorflow,']\n",
                        "\n",
                        "Recommended Courses to fill gaps:\n",
                        "                                            course_name course_level  \\\n",
                        "1394  IDM International Foundation Diploma in Computing      Diploma   \n",
                        "2649                   Graduate Diploma in Data Science      Diploma   \n",
                        "1401             IDM International Diploma in Computing      Diploma   \n",
                        "\n",
                        "      match_score  \n",
                        "1394     0.401598  \n",
                        "2649     0.388976  \n",
                        "1401     0.379758  \n"
                    ]
                }
            ],
            "source": [
                "def recommend_upskilling(user_level, gaps):\n",
                "    \"\"\"\n",
                "    user_level: Professional, Student, etc.\n",
                "    gaps: List of missing skills found above\n",
                "    \"\"\"\n",
                "    print(f\"\\nFinding Courses for {user_level} to learn: {gaps}\")\n",
                "    \n",
                "    # 1. Filter Courses by Level Logic\n",
                "    if user_level == \"Professional\":\n",
                "        # Professionals usually want Masters or specialized certs\n",
                "        candidates = courses_df[courses_df['course_level'].isin(['Postgraduate', 'Certificate'])]\n",
                "    else:\n",
                "        # Students need Degrees or Diplomas\n",
                "        candidates = courses_df[courses_df['course_level'].isin(['Undergraduate', 'Diploma'])]\n",
                "        \n",
                "    # 2. Semantic Search against Gaps\n",
                "    gap_text = \" \".join(gaps)\n",
                "    gap_emb = model.encode(gap_text)\n",
                "    \n",
                "    # Calculate similarity on the filtered set\n",
                "    candidates = candidates.copy()\n",
                "    candidate_texts = candidates.apply(lambda x: safe_text(x, ['course_name', 'description']), axis=1).tolist()\n",
                "    \n",
                "    if not candidate_texts: return pd.DataFrame() # No candidates\n",
                "    \n",
                "    cand_embs = model.encode(candidate_texts)\n",
                "    scores = util.cos_sim(gap_emb, cand_embs)[0]\n",
                "    \n",
                "    candidates['match_score'] = scores.cpu().numpy()\n",
                "    return candidates.sort_values('match_score', ascending=False).head(3)\n",
                "\n",
                "# DEMO\n",
                "courses_rec = recommend_upskilling(\"Student\", gaps)\n",
                "print(\"\\nRecommended Courses to fill gaps:\")\n",
                "print(courses_rec[['course_name', 'course_level', 'match_score']])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
